{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kQQuxm6USWe"
      },
      "source": [
        "# Perpetual American example\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ri5r6bp3USWf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "from tqdm import tqdm, trange\n",
        "from math import exp, sqrt, log\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from scipy.special import i0, i1, iv\n",
        "from numpy import random\n",
        "from torch.nn.functional import normalize\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib qt\n",
        "\n",
        "import scipy.optimize as opt\n",
        "import copy as copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dtgNI6YnUSWg"
      },
      "outputs": [],
      "source": [
        "#from torch.utils.tensorboard import SummaryWriter\n",
        "#writer = SummaryWriter()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "K4unI4tqUSWg"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
        "#device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "j6OZ0n4ZUSWh"
      },
      "outputs": [],
      "source": [
        "class PDEQnet(nn.Module):\n",
        "  def __init__(self, dim, width, beta):\n",
        "    super(PDEQnet, self).__init__()\n",
        "    self.dim = dim\n",
        "    self.width = width\n",
        "    self.innerwidth = int(width/2)\n",
        "    self.beta = beta\n",
        "\n",
        "    self.wb = nn.Linear(self.dim, self.innerwidth).to(device)\n",
        "    self.wb2 = nn.Linear(self.innerwidth, self.width).to(device)\n",
        "    self.c = nn.Linear(self.width, 1, bias=False).to(device)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.wb(x)\n",
        "    x = torch.sigmoid(x)\n",
        "    #x = 1/(1+torch.pow(x,2))\n",
        "    x = self.wb2(x)\n",
        "    x = torch.sigmoid(x)\n",
        "    #x = 1/(1+torch.pow(x,2))\n",
        "    x = self.c(x)\n",
        "    return x\n",
        "\n",
        "  def assign_value(self):\n",
        "    self.c.weight.data = torch.as_tensor(np.random.uniform(-1, 1, size=self.c.weight.shape), dtype=torch.float32).to(device)\n",
        "    self.wb.weight.data = torch.as_tensor(np.random.normal(0, 1, size=self.wb.weight.shape),  dtype=torch.float32).to(device)\n",
        "    self.wb.bias.data = torch.as_tensor(np.random.normal(0, 1, size=self.wb.bias.shape) ,dtype=torch.float32).to(device)\n",
        "    self.wb2.weight.data = torch.as_tensor(np.random.normal(0, 1, size=self.wb2.weight.shape),  dtype=torch.float32).to(device)\n",
        "    self.wb2.bias.data = torch.as_tensor(np.random.normal(0, 1, size=self.wb2.bias.shape) ,dtype=torch.float32).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QKXV8Kj3USWi"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "dim = 1\n",
        "gamma = 0.05\n",
        "sigma2_2 = (0.25**2)/2 #sigma^2/2\n",
        "#d = [1 for i in range(dim)]\n",
        "K=0.5\n",
        "\n",
        "\n",
        "# Hyper parameters\n",
        "N = 2**8\n",
        "beta = 0.5+0.01\n",
        "# Learning rate\n",
        "initial_lr = 0.05 * N**(2*beta-1)\n",
        "\n",
        "# Auxiliary functions\n",
        "def eta(grid):\n",
        "  res = grid*(1.-grid)\n",
        "  return res\n",
        "\n",
        "\n",
        "\n",
        "# Monte Carlo\n",
        "Nmc_max = 2000\n",
        "Nmc_initial = 500\n",
        "Nbasepoints = int(1e7)\n",
        "# Default type\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "#True solution (to give right boundary)\n",
        "m = (-(gamma-sigma2_2) - sqrt((gamma-sigma2_2)**2 + 4*sigma2_2*gamma))/(2*sigma2_2)\n",
        "Sstar = m*K/(m-1)\n",
        "def Vtrue_scalar(s):\n",
        "    if s>Sstar:\n",
        "        return (K-Sstar)*(s/Sstar)**m\n",
        "    else:\n",
        "        return (K-s)\n",
        "def Vtrue(s):\n",
        "    return np.array([Vtrue_scalar(x) for x in s])\n",
        "\n",
        "Rightval = Vtrue_scalar(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "pAobmnpKUSWi"
      },
      "outputs": [],
      "source": [
        "# Q fit, fixed grid\n",
        "qnet= PDEQnet(dim, N, beta).to(device)\n",
        "# initialization of PDEQnet paramters\n",
        "qnet.assign_value()\n",
        "qnet2 = copy.deepcopy(qnet)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4FeS4VbUSWj",
        "outputId": "078962cc-a791-4aa7-95a1-4baa24cb3dc0"
      },
      "outputs": [],
      "source": [
        "#qnet.load_state_dict(torch.load('/content/6d, Q-learning, 30k epochs.pkl'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create reservoir of points, so we don't have to sample every loop\n",
        "#this is maybe the one thing that's worth doing on a GPU\n",
        "\n",
        "#source = torch.randn(size=(Nbasepoints, dim))\n",
        "#source = normalize(source, p=2.0) #Normalize to sphere\n",
        "#radius = torch.rand(size = (Nbasepoints,1))\n",
        "#radius = torch.pow(torch.rand(size = (Nbasepoints,1)),1/dim)\n",
        "#source = radius*source #renormalize\n",
        "\n",
        "source = torch.rand(size=(Nbasepoints,dim))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dk8QAmWgUSWk",
        "outputId": "d23ac1fa-7eb8-4254-b3ba-f252211ad845"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [01:43<00:00, 96.81it/s]\n"
          ]
        }
      ],
      "source": [
        "#Training algorithm, main\n",
        "#torch.autograd.detect_anomaly()\n",
        "# Num of epoch\n",
        "Num_epo = 10000\n",
        "\n",
        "# Loss level\n",
        "loss_list = []\n",
        "\n",
        "# Optmizer, scheduler\n",
        "Qoptimizer = optim.RMSprop(qnet.parameters(), lr = initial_lr, alpha = 0.99, eps = 1e-08)\n",
        "Qscheduler = LambdaLR(Qoptimizer, lr_lambda= lambda epoch: initial_lr/(1+(epoch/500)))\n",
        "\n",
        "fig, axs = plt.subplots(2,1)\n",
        "\n",
        "# Training\n",
        "for count in trange(Num_epo):\n",
        "\n",
        "  Nmc = int(Nmc_initial+(Nmc_max-Nmc_initial)*(1+count)/(1+Num_epo))\n",
        "  epoch_sample = torch.randint(0,len(source), (Nmc,1))\n",
        "\n",
        "  grid = source[epoch_sample].clone().detach()\n",
        "  grid.requires_grad = True\n",
        "  \n",
        "  # Net output\n",
        "  v = qnet(grid)\n",
        "  v = v*eta(grid).reshape(v.shape) + (K-Rightval)*(1-grid)+Rightval # to give value of K at 0, 0 at 1\n",
        "\n",
        "\n",
        "  # Tensor reshape\n",
        "  v_r =  torch.reshape(v, (-1,))\n",
        "  # Compute partial derivatives and the Laplacian\n",
        "  dv_dx = torch.autograd.grad(v, grid, grad_outputs = torch.ones(grid.size()), create_graph = True)[0]\n",
        "  d2v_dx2 = torch.autograd.grad(dv_dx, grid, grad_outputs = torch.ones(grid.size()), create_graph = True)[0]\n",
        "  dv_dx = torch.reshape(dv_dx, (-1,))\n",
        "  d2v_dx2 = torch.reshape(d2v_dx2, (-1,))\n",
        "  \n",
        "  #evaluate PDE operator\n",
        "  lq = -gamma*v_r+ gamma*grid.reshape(-1)*dv_dx + torch.pow(grid.reshape(-1),2)*sigma2_2*d2v_dx2\n",
        "  lq2 = torch.maximum((K-grid.reshape(-1)), torch.zeros_like(v_r)) - v_r\n",
        "  #lq2 = K-grid.reshape(-1)-v_r\n",
        "  lq = torch.maximum(lq, lq2)\n",
        "  #LQ = lq.clone().detach()\n",
        "  LQ=lq\n",
        "\n",
        "  # Q-learning\n",
        "  #loss_to_min =-1* torch.dot(LQ, v_r)\n",
        "  loss_to_min = torch.dot(LQ, LQ)\n",
        "\n",
        "  #with torch.cuda.stream(s):\n",
        "  Qoptimizer.zero_grad()\n",
        "  loss_to_min.backward()\n",
        "  Qoptimizer.step()\n",
        "  Qscheduler.step()\n",
        "\n",
        "  loss = float(torch.dot(LQ, LQ))\n",
        "  loss/= Nmc\n",
        "  loss_list.append(loss)\n",
        "\n",
        "  if count%20 == 0:\n",
        "    axs[0].clear()\n",
        "    axs[1].clear()\n",
        "    axs[0].scatter(grid.detach().cpu(),v_r.detach().cpu())\n",
        "    axs[1].scatter(grid.detach().cpu(), LQ.detach().cpu())\n",
        "    plt.pause(0.01)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dk8QAmWgUSWk",
        "outputId": "d23ac1fa-7eb8-4254-b3ba-f252211ad845"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [01:17<00:00, 128.74it/s]\n"
          ]
        }
      ],
      "source": [
        "#Training algorithm, main\n",
        "#torch.autograd.detect_anomaly()\n",
        "# Num of epoch\n",
        "Num_epo = 10000\n",
        "\n",
        "# Loss level\n",
        "loss_list2 = []\n",
        "\n",
        "# Optmizer, scheduler\n",
        "Qoptimizer = optim.RMSprop(qnet2.parameters(), lr = initial_lr, alpha = 0.99, eps = 1e-08)\n",
        "Qscheduler = LambdaLR(Qoptimizer, lr_lambda= lambda epoch: initial_lr/(1+(epoch/500)))\n",
        "\n",
        "fig, axs = plt.subplots(2,1)\n",
        "\n",
        "# Training\n",
        "for count in trange(Num_epo):\n",
        "\n",
        "  Nmc = int(Nmc_initial+(Nmc_max-Nmc_initial)*(1+count)/(1+Num_epo))\n",
        "  epoch_sample = torch.randint(0,len(source), (Nmc,1))\n",
        "\n",
        "  grid = source[epoch_sample].clone().detach()\n",
        "  grid.requires_grad = True\n",
        "  \n",
        "  # Net output\n",
        "  v = qnet2(grid)\n",
        "  v = v*eta(grid).reshape(v.shape) + (K-Rightval)*(1-grid)+Rightval # to give value of K at 0, 0 at 1\n",
        "\n",
        "\n",
        "  # Tensor reshape\n",
        "  v_r =  torch.reshape(v, (-1,))\n",
        "  # Compute partial derivatives and the Laplacian\n",
        "  dv_dx = torch.autograd.grad(v, grid, grad_outputs = torch.ones(grid.size()), create_graph = True)[0]\n",
        "  d2v_dx2 = torch.autograd.grad(dv_dx, grid, grad_outputs = torch.ones(grid.size()), create_graph = True)[0]\n",
        "  dv_dx = torch.reshape(dv_dx, (-1,))\n",
        "  d2v_dx2 = torch.reshape(d2v_dx2, (-1,))\n",
        "  \n",
        "  #evaluate PDE operator\n",
        "  lq = -gamma*v_r+ gamma*grid.reshape(-1)*dv_dx + torch.pow(grid.reshape(-1),2)*sigma2_2*d2v_dx2\n",
        "  lq2 = torch.maximum((K-grid.reshape(-1)), torch.zeros_like(v_r)) - v_r\n",
        "  #lq2 = K-grid.reshape(-1)-v_r\n",
        "  lq = torch.maximum(lq, lq2)\n",
        "  LQ = lq.clone().detach()\n",
        "  #LQ=lq\n",
        "\n",
        "  # Q-learning\n",
        "  loss_to_min =-1* torch.dot(LQ, v_r)\n",
        "  #loss_to_min = torch.dot(LQ, LQ)\n",
        "\n",
        "  #with torch.cuda.stream(s):\n",
        "  Qoptimizer.zero_grad()\n",
        "  loss_to_min.backward()\n",
        "  Qoptimizer.step()\n",
        "  Qscheduler.step()\n",
        "\n",
        "  loss = float(torch.dot(LQ, LQ))\n",
        "  loss/= Nmc\n",
        "  loss_list2.append(loss)\n",
        "\n",
        "  if count%20 == 0:\n",
        "    axs[0].clear()\n",
        "    axs[1].clear()\n",
        "    axs[0].scatter(grid.detach().cpu(),v_r.detach().cpu())\n",
        "    axs[1].scatter(grid.detach().cpu(), LQ.detach().cpu())\n",
        "    plt.pause(0.01)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lT6HSkdEUSWm"
      },
      "outputs": [],
      "source": [
        "#model_save_name = 'BM, 6d, 30k epochs.pkl'\n",
        "#path = F\"/content/{model_save_name}\" \n",
        "#torch.save(qnet.state_dict(), path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "w2IaSkcpUSWm",
        "outputId": "45aee8d8-4ee4-486a-edcc-192a4d2b18e0"
      },
      "outputs": [],
      "source": [
        "# Loss level\n",
        "plt.figure(figsize=(7,4.5))\n",
        "#ax = fig.add_subplot(1, 2, 1)\n",
        "#axis=[i for i in range(Num_epo)]\n",
        "axis = np.cumsum([1/(1+(i//500)) for i in range(len(loss_list))])\n",
        "plt.xlabel('Cumulative training time')\n",
        "plt.ylabel('Loss level')\n",
        "plt.yscale('log') \n",
        "fig1 = plt.plot(axis,loss_list,'blue')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Loss level\n",
        "plt.figure(figsize=(7,4.5))\n",
        "#ax = fig.add_subplot(1, 2, 1)\n",
        "axis=[i for i in range(len(loss_list))]\n",
        "plt.xlabel('Training epoch')\n",
        "plt.ylabel('Loss level')\n",
        "plt.yscale('log') \n",
        "fig1 = plt.plot(axis,loss_list,'blue')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x16ca6c4d270>]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Loss level\n",
        "plt.figure(figsize=(7,4.5))\n",
        "#ax = fig.add_subplot(1, 2, 1)\n",
        "axis=[i for i in range(len(loss_list))]\n",
        "plt.xlabel('Training epoch')\n",
        "plt.ylabel('Loss level')\n",
        "plt.yscale('log') \n",
        "plt.plot(axis,loss_list,'red')\n",
        "plt.plot(axis,loss_list2,'blue')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "D_Xm8eAbUSWm",
        "outputId": "49cc20b7-58aa-426d-b3d1-99f9e419e639"
      },
      "outputs": [],
      "source": [
        "log_loss_list = [log(x) for x in loss_list]\n",
        "plt.figure(figsize=(7,4.5))\n",
        "#ax = fig.add_subplot(1, 2, 1)\n",
        "axis=[i for i in range(Num_epo)]\n",
        "plt.xlabel('Number of epochs')\n",
        "plt.ylabel('Loss level')\n",
        "fig1 = plt.plot(axis[400:600], log_loss_list[400:600],'blue')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\samue\\AppData\\Local\\Temp/ipykernel_15808/901743688.py:10: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  return np.array([Vtrue_scalar(x) for x in s])\n",
            "C:\\Users\\samue\\AppData\\Local\\Temp/ipykernel_15808/901743688.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  return np.array([Vtrue_scalar(x) for x in s])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x16d51618d00>]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sgrid = torch.linspace(0,1,100).reshape(100,1)\n",
        "v = qnet(sgrid)\n",
        "v = v*eta(sgrid).reshape(v.shape) + (K-Rightval)*(1-sgrid)+Rightval # to give value of K at 0, 0 at 1\n",
        "v2 = qnet2(sgrid)\n",
        "v2 = v2*eta(sgrid).reshape(v2.shape) + (K-Rightval)*(1-sgrid)+Rightval # to give value of K at 0, 0 at 1\n",
        "plt.scatter(sgrid.detach().cpu(), v.detach().cpu())\n",
        "plt.scatter(sgrid.detach().cpu(), v2.detach().cpu(), color='green')\n",
        "plt.plot(sgrid.detach().cpu(), Vtrue(sgrid.detach().cpu()), color='red')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Q-PDE playground.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
